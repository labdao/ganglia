{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "# this can disapear once plex is a pip package\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import plex.sdk\n",
    "importlib.reload(plex.sdk)\n",
    "\n",
    "os.environ[\"PLEX_ACCESS_TOKEN\"] = \"mellon\"\n",
    "os.environ[\"PLEX_ENV\"] = \"stage\"\n",
    "os.environ[\"DOCKER_DEFAULT_PLATFORM\"] = \"linux/x86_64/v8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "Created IO Graph of length 6\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def create_pdbind_io_dict(csv_path, pdbbind_data_root, size=float('inf')):\n",
    "    io_graph = []\n",
    "\n",
    "    i = 0\n",
    "    with open(csv_path, 'r') as csvfile:\n",
    "        csvreader = csv.DictReader(csvfile)\n",
    "\n",
    "        for row in csvreader:\n",
    "            protein_path = os.path.join(pdbbind_data_root, row['protein_path'])\n",
    "            ligand_path = os.path.join(pdbbind_data_root, row['ligand_description'])\n",
    "\n",
    "            if not os.path.exists(protein_path) or not os.path.exists(ligand_path):\n",
    "                print(f\"Skipping row {row['complex_name']} due to missing file(s).\")\n",
    "                continue\n",
    "\n",
    "            io_subgraph = [{\n",
    "                \"tool\": \"tools/equibind.json\",\n",
    "                \"inputs\": {\n",
    "                    \"protein\": {\n",
    "                        \"class\": \"File\",\n",
    "                        \"filepath\": protein_path\n",
    "                    },\n",
    "                    \"small_molecule\": {\n",
    "                        \"class\": \"File\",\n",
    "                        \"filepath\": ligand_path\n",
    "                    }\n",
    "                },\n",
    "                \"outputs\": {\n",
    "                    \"best_docked_small_molecule\": {\n",
    "                        \"class\": \"File\",\n",
    "                        \"filepath\": \"\"\n",
    "                    },\n",
    "                    \"protein\": {\n",
    "                        \"class\": \"File\",\n",
    "                        \"filepath\": \"\"\n",
    "                    }\n",
    "                },\n",
    "                \"state\": \"created\",\n",
    "                \"errMsg\": \"\"\n",
    "            },\n",
    "            {\n",
    "                \"tool\": \"tools/oddt.json\",\n",
    "                \"inputs\": {\n",
    "                    \"protein\": {\n",
    "                        \"class\": \"File\",\n",
    "                        \"filepath\": f\"${{{i * 3}[protein]}}\"\n",
    "                    },\n",
    "                    \"small_molecule\": {\n",
    "                        \"class\": \"File\",\n",
    "                        \"filepath\": f\"${{{i * 3}[best_docked_small_molecule]}}\"\n",
    "                    }\n",
    "                },\n",
    "                \"outputs\": {\n",
    "                    \"best_docked_small_molecule\": {\n",
    "                        \"class\": \"File\",\n",
    "                        \"filepath\": \"\"\n",
    "                    },\n",
    "                    \"protein\": {\n",
    "                        \"class\": \"File\",\n",
    "                        \"filepath\": \"\"\n",
    "                    }\n",
    "                },\n",
    "                \"state\": \"created\",\n",
    "                \"errMsg\": \"\" \n",
    "            },\n",
    "            {\n",
    "                \"outputs\": {\n",
    "                    \"scored_small_molecule\": {\n",
    "                        \"class\": \"File\",\n",
    "                        \"filepath\": \"\"\n",
    "                    },\n",
    "                    \"scores\": {\n",
    "                        \"class\": \"File\",\n",
    "                        \"filepath\": \"\"\n",
    "                    }\n",
    "                },\n",
    "                \"tool\": \"tools/openbabel/rmsd-openbabel.json\",\n",
    "                \"inputs\": {\n",
    "                    \"reference_structure\": {\n",
    "                        \"class\": \"File\",\n",
    "                        \"filepath\": f\"${{{i * 3}[protein]}}\"\n",
    "                    },\n",
    "                    \"comparison_structure\": {\n",
    "                        \"class\": \"File\",\n",
    "                        \"filepath\": f\"${{{i * 3}[best_docked_small_molecule]}}\"\n",
    "                    }\n",
    "                },\n",
    "                \"state\": \"created\",\n",
    "                \"errMsg\": \"\"\n",
    "            }]\n",
    "\n",
    "            print(i)\n",
    "            i += 1\n",
    "            io_graph += io_subgraph\n",
    "            if i >= size:\n",
    "                break\n",
    "    return io_graph\n",
    "\n",
    "# for local mac\n",
    "io_graph = create_pdbind_io_dict(\"/Users/mcmenemy/Documents/diffdock_testdata.csv\", \"/Users/mcmenemy/Documents\", 2)\n",
    "print(f\"Created IO Graph of length {len(io_graph)}\")\n",
    "# for linux\n",
    "# io_graph = create_pdbind_io_dict(\"/home/ubuntu/datasets/diffdock_testdata.csv\", \"/home/ubuntu\", 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plex version (v0.6.1) up to date.\n",
      "BACALHAU_API_HOST not set, using default host\n",
      "toolPath \n",
      "Running IPWL io path\n",
      "Created working directory:  /Users/mcmenemy/code/plex/736a551f-f9ed-4d31-bf35-d3916173f37a\n",
      "Reading IO Entries from:  /var/folders/yh/vwqzmpsd55xchsjvhxvbnqvh0000gn/T/tmput34gslo/io_data.json\n",
      "Initialized IO file at:  /Users/mcmenemy/code/plex/736a551f-f9ed-4d31-bf35-d3916173f37a/io.json\n",
      "Processing IO Entries\n",
      "/Users/mcmenemy/code/plex/736a551f-f9ed-4d31-bf35-d3916173f37a\n",
      "/Users/mcmenemy/code/plex/736a551f-f9ed-4d31-bf35-d3916173f37a/io.json\n",
      "Starting to process IO entry 5 \n",
      "Starting to process IO entry 2 \n",
      "IO Subgraph at 5 is still waiting on inputs to complete \n",
      "Success processing IO entry 5 \n",
      "Starting to process IO entry 3 \n",
      "IO Subgraph at 2 is still waiting on inputs to complete \n",
      "Success processing IO entry 2 \n",
      "Starting to process IO entry 4 \n",
      "IO Subgraph at 4 is still waiting on inputs to complete \n",
      "Success processing IO entry 4 \n",
      "Starting to process IO entry 0 \n",
      "Generated docker cmd: docker run  -v /Users/mcmenemy/code/plex/736a551f-f9ed-4d31-bf35-d3916173f37a/entry-3/inputs:/inputs -v /Users/mcmenemy/code/plex/736a551f-f9ed-4d31-bf35-d3916173f37a/entry-3/outputs:/outputs ghcr.io/labdao/equibind:main@sha256:21a381d9ab1ff047565685044569c8536a55e489c9531326498b28d6b3cc244f /bin/bash -c \"mkdir -p /tmp-inputs/tmp; mkdir -p /tmp-outputs/tmp; cp /inputs/* /tmp-inputs/tmp/; ls /tmp-inputs/tmp; cd /src && python /src/inference.py --config=/src/configs_clean/bacalhau.yml; mv /tmp-outputs/tmp/* /outputs/; mv /outputs/lig_equibind_corrected.sdf /outputs/6d08_protein_processed_6d08_ligand_docked.sdf; mv /tmp-inputs/tmp/*.pdb /outputs/;\"\n",
      "Generated docker cmd: docker run  -v /Users/mcmenemy/code/plex/736a551f-f9ed-4d31-bf35-d3916173f37a/entry-0/inputs:/inputs -v /Users/mcmenemy/code/plex/736a551f-f9ed-4d31-bf35-d3916173f37a/entry-0/outputs:/outputs ghcr.io/labdao/equibind:main@sha256:21a381d9ab1ff047565685044569c8536a55e489c9531326498b28d6b3cc244f /bin/bash -c \"mkdir -p /tmp-inputs/tmp; mkdir -p /tmp-outputs/tmp; cp /inputs/* /tmp-inputs/tmp/; ls /tmp-inputs/tmp; cd /src && python /src/inference.py --config=/src/configs_clean/bacalhau.yml; mv /tmp-outputs/tmp/* /outputs/; mv /outputs/lig_equibind_corrected.sdf /outputs/6qqw_protein_processed_6qqw_ligand_docked.mol2; mv /tmp-inputs/tmp/*.pdb /outputs/;\"\n",
      "Docker ran with output: 6d08_ligand.sdf\n",
      "6d08_protein_processed.pdb\n",
      "DGL backend not selected or invalid.  Assuming PyTorch for now.\n",
      "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n",
      "[2023-05-06 21:59:21.665379] [ Using Seed :  1  ]\n",
      "\n",
      "Processing tmp: complex 1 of 1\n",
      "Trying to load /tmp-inputs/tmp/6d08_ligand.sdf\n",
      "Docking the receptor /tmp-inputs/tmp/6d08_protein_processed.pdb\n",
      "To the ligand /tmp-inputs/tmp/6d08_ligand.sdf\n",
      "Writing prediction to /tmp-outputs/tmp/lig_equibind_corrected.sdf\n",
      "Saving predictions to runs/flexible_self_docking/predictions_RDKitFalse.pt\n",
      " \n",
      "Success processing IO entry 3 \n",
      "Starting to process IO entry 1 \n",
      "IO Subgraph at 1 is still waiting on inputs to complete \n",
      "Success processing IO entry 1 \n",
      "Docker ran with output: 6qqw_ligand.mol2\n",
      "6qqw_protein_processed.pdb\n",
      "DGL backend not selected or invalid.  Assuming PyTorch for now.\n",
      "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n",
      "[2023-05-06 21:59:21.751628] [ Using Seed :  1  ]\n",
      "\n",
      "Processing tmp: complex 1 of 1\n",
      "Trying to load /tmp-inputs/tmp/6qqw_ligand.mol2\n",
      "Docking the receptor /tmp-inputs/tmp/6qqw_protein_processed.pdb\n",
      "To the ligand /tmp-inputs/tmp/6qqw_ligand.mol2\n",
      "Writing prediction to /tmp-outputs/tmp/lig_equibind_corrected.sdf\n",
      "Saving predictions to runs/flexible_self_docking/predictions_RDKitFalse.pt\n",
      " \n",
      "Success processing IO entry 0 \n",
      "Starting to process IO entry 5 \n",
      "Starting to process IO entry 1 \n",
      "Generated docker cmd: docker run  -v /Users/mcmenemy/code/plex/736a551f-f9ed-4d31-bf35-d3916173f37a/entry-5/inputs:/inputs -v /Users/mcmenemy/code/plex/736a551f-f9ed-4d31-bf35-d3916173f37a/entry-5/outputs:/outputs quay.io/labdao/openbabel@sha256:1087315d7eda6d0632c9f9df72500ab9f6fef612c79bae7410473a2336f7be34 /bin/bash -c \"echo 'reference,comparison,RMSD' > /outputs/rmsd.csv && echo -n '6d08_protein_processed,6d08_protein_processed_6d08_ligand_docked,' > /outputs/temp.csv && obrms -firstonly /inputs/6d08_protein_processed.pdb /inputs/6d08_protein_processed_6d08_ligand_docked.sdf | awk '{print $2}' | tr -d '\\n' >> /outputs/temp.csv && cat /outputs/temp.csv >> /outputs/rmsd.csv && rm /outputs/temp.csv;\"\n",
      "Generated docker cmd: docker run  -v /Users/mcmenemy/code/plex/736a551f-f9ed-4d31-bf35-d3916173f37a/entry-1/inputs:/inputs -v /Users/mcmenemy/code/plex/736a551f-f9ed-4d31-bf35-d3916173f37a/entry-1/outputs:/outputs ghcr.io/labdao/oddt:main /bin/bash -c \"mkdir -p /tmp-out && oddt_cli /inputs/6qqw_protein_processed_6qqw_ligand_docked.mol2 --receptor /inputs/6qqw_protein_processed.pdb --score rfscore_v1 --score rfscore_v2 --score rfscore_v3 --score nnscore -O /tmp-out/6qqw_protein_processed_6qqw_protein_processed_6qqw_ligand_docked_scored.mol2 && cd /tmp-out && /app/aggregate_score.sh && cp /tmp-out/* /outputs\"\n",
      "Docker ran with output:  \n",
      "Success processing IO entry 5 \n",
      "Starting to process IO entry 2 \n",
      "Generated docker cmd: docker run  -v /Users/mcmenemy/code/plex/736a551f-f9ed-4d31-bf35-d3916173f37a/entry-2/inputs:/inputs -v /Users/mcmenemy/code/plex/736a551f-f9ed-4d31-bf35-d3916173f37a/entry-2/outputs:/outputs quay.io/labdao/openbabel@sha256:1087315d7eda6d0632c9f9df72500ab9f6fef612c79bae7410473a2336f7be34 /bin/bash -c \"echo 'reference,comparison,RMSD' > /outputs/rmsd.csv && echo -n '6qqw_protein_processed,6qqw_protein_processed_6qqw_ligand_docked,' > /outputs/temp.csv && obrms -firstonly /inputs/6qqw_protein_processed.pdb /inputs/6qqw_protein_processed_6qqw_ligand_docked.mol2 | awk '{print $2}' | tr -d '\\n' >> /outputs/temp.csv && cat /outputs/temp.csv >> /outputs/rmsd.csv && rm /outputs/temp.csv;\"\n",
      "Docker ran with output:  \n",
      "Success processing IO entry 2 \n",
      "Starting to process IO entry 4 \n",
      "Generated docker cmd: docker run  -v /Users/mcmenemy/code/plex/736a551f-f9ed-4d31-bf35-d3916173f37a/entry-4/inputs:/inputs -v /Users/mcmenemy/code/plex/736a551f-f9ed-4d31-bf35-d3916173f37a/entry-4/outputs:/outputs ghcr.io/labdao/oddt:main /bin/bash -c \"mkdir -p /tmp-out && oddt_cli /inputs/6d08_protein_processed_6d08_ligand_docked.sdf --receptor /inputs/6d08_protein_processed.pdb --score rfscore_v1 --score rfscore_v2 --score rfscore_v3 --score nnscore -O /tmp-out/6d08_protein_processed_6d08_protein_processed_6d08_ligand_docked_scored.sdf && cd /tmp-out && /app/aggregate_score.sh && cp /tmp-out/* /outputs\"\n",
      "Docker ran with output: /opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_base.py:235: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_base.py:235: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_base.py:235: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1\n",
      "  n_jobs = min(effective_n_jobs(n_jobs), n_estimators)\n",
      " \n",
      "Success processing IO entry 4 \n",
      "Docker ran with output: Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/oddt/virtualscreening.py\", line 340, in fetch\n",
      "    first_chunk = next(chunk_feed)\n",
      "StopIteration\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/bin/oddt_cli\", line 283, in <module>\n",
      "    main()\n",
      "  File \"/opt/conda/bin/oddt_cli\", line 267, in main\n",
      "    pipeline.write(fmt, args.out_file)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/oddt/virtualscreening.py\", line 413, in write\n",
      "    for mol in self.fetch():\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/oddt/virtualscreening.py\", line 342, in fetch\n",
      "    raise StopIteration('There are no molecules loaded to the pipeline.')\n",
      "StopIteration: There are no molecules loaded to the pipeline.\n",
      " \n",
      "Error processing IO entry 1 \n",
      "error running Docker cmd: error running Docker command: exit status 1, output: Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/oddt/virtualscreening.py\", line 340, in fetch\n",
      "    first_chunk = next(chunk_feed)\n",
      "StopIteration\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/bin/oddt_cli\", line 283, in <module>\n",
      "    main()\n",
      "  File \"/opt/conda/bin/oddt_cli\", line 267, in main\n",
      "    pipeline.write(fmt, args.out_file)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/oddt/virtualscreening.py\", line 413, in write\n",
      "    for mol in self.fetch():\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/oddt/virtualscreening.py\", line 342, in fetch\n",
      "    raise StopIteration('There are no molecules loaded to the pipeline.')\n",
      "StopIteration: There are no molecules loaded to the pipeline.\n",
      "\n",
      "Finished processing, results written to /Users/mcmenemy/code/plex/736a551f-f9ed-4d31-bf35-d3916173f37a/io.json"
     ]
    }
   ],
   "source": [
    "from plex.sdk import run_plex\n",
    "\n",
    "run_plex(io_graph, local=True, verbose=True, concurrency=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
